---
layout: post
title: "Multiple Comparisons: Bonferroni and FDR"
date: 2015-04-01
---
Statistical tests are generally called significant and the null hypothesis is rejected if the p-value (the probability of seeing certain value of a specific test statistic provided that the null hypothesis is true) falls below a predefined alpha value, which is nearly always set to 0.05. This means that 5% of the time, the null hypothesis is rejected when in fact it is true and we detect a false positive. This probability is relative to a single statistical test. In the case of GWAS, hundreds of thousands to millions of tests are conducted, each for a loci and with its own false positive probability. The cumulative likelihood of finding one or more false positives over the entire GWAS analysis is therefore much higher.

If we test 100,000 loci for association at the 5% level we should expect about 5,000 false positives. Thus, if we want the overall Type I error to remain at 5% we need to lower the significance level at each locus. There are several methods and I will focus on Bonferroni correction and False Discovery Rate (FDR) in this post. Bonferroni correction simply divides the significance level at each locus by the number of tests. In other words, it adjusts the alpha value from a = 0.05 to a =(0.05/k) where k is the number of statistical tests conducted. If the tests are independent then the Bonferroni bound provides a slightly conservative bound. If the tests are correlated then the bound becomes more conservative. Due to linkage disequilibrium among GWAS markers, it is generally untrue to assume that each association test on a GWAS data set is independent. Thus, applying Bonferroni correction often gives us the most conservative p-value threshold (maybe as a lower bound?) -- for a typical GWAS using 500,000 SNPs, statistical significance of a SNP association would be set as low as 1e-7.

An alternative to adjusting the false positive rate (alpha) is to determine the false discovery rate (FDR). The false discovery rate is an estimate of the proportion of significant results (usually at alpha = 0.05) that are false positives (i.e., the proportion of positive tests that are false). Under the null hypothesis that there are no true associations in a GWAS dataset, p values for association tests would follow a uniform distribution (evenly distributed from 0 to 1). Originally developed by Benjamini and Hochberg (1990; 1995), FDR procedurs essentially correct for this number of expected false discoveries, providing an estimate of the number of actual true results among those called significant. These techniques have been widely applied to GWAS and extended in a variety of ways.

Permutation testing is another approach for establishing significance in GWAS. While somewhat computationally intensive, permutation testing is a straightforward way to generate the empirical distribution of test statistics for a given dataset when the null hypothesis is true. This is achieved by randomly reassigning the phenotypes of each individual to another individual in the dataset, effectively breaking the genotype-phenotype relationship of the dataset. Each random reassignment of the data represents one possible sampling of individuals under the null hypothesis, and this process is repeated a predefined number of times N to generate an empirical distribution with resolution N, so a permutation procedure with an N of 1000 gives an empirical pvalue within 1/1000th of a decimal place. Several software packages have been developed to perform permutation testing for GWAS studies, including the popular PLINK software, PRESTO, and PERMORY.

Another commonly used approach is to rely on the concept of genome-wide significance. Based on the distribution of LD in the genome for a specific population, there are an "effective" number of independent genomic regions, and thus an effective number of statistical tests that should be corrected for. For European descent populations, this threshold has been estimated at 7.2e-8 (Dudbridge & Gusnanto, 2008). This reasonable approach should be used with caution, however, as the only scenario where this correction is appropriate is when hypotheses are tested on the genome scale. Candidate gene studies or replication studies with a focused hypothesis do not require correction to this level, as the number of effective, independent statistical tests is much, much lower than what is assumed for genome-wide significance.

<h2>References</h2>
<ul>
<li>Benjamini and Hochberg (1995) Controlling the false discovery rate: a practical and powerful approach to multiple testing. JRSS(B) 57:289-300</li>
<li>Dudbridge F, Gusnanto A (2008) Estimation of significance thresholds for genomewide association scans. Genet Epidemiol 32: 227–234</li>
<li>Hochberg Y, Benjamini Y (1990) More powerful procedures for multiple significance testing. Stat Med 9: 811–818.</li>
<li>van den Oord EJ (2008) Controlling false discoveries in genetic studies. Am J Med Genet B Neuropsychiatr Genet 147B: 637–644.</li>
</ul>
