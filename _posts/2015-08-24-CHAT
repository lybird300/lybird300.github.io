---
layout: post
title: "CHAT"
date: 2015-08-24
---
Today I'm starting this post to record my thoughts while looking into Kirk's self-written software -- CHAT. Although I don't know (a) how often I will update, (b) how useful the content will be, or (c) how long it will take to complete the post, it is pretty exiting that after almost 5 months I'm finally here! ^_^

During the past 6+ years Kirk has been working on CHAT alone in his spare time. Now Charles and me are helping him publicize this software. To start with let me give you a brief introduction of CHAT. CHAT stands for Convergent Haplotype Association Tagging. It is a computer program that we are developing to detect rare moderate penetrant mutations from GWA data sets. <b>The core of this method is a graph-theory based algorithm that systematically searches for subsets of individuals that share long range haplotypes</b>. The underlying assumption is that a small (but significant) subset of unrelated individuals have the same disease because they have inherited a moderate penetrant mutation from a distant common ancestor. Since the algorithm is computationally intensive (an NP-complete problem), we have been cooperating with the Renaissance Computational Institute (RENCI) and using their high-performance computing clusters. How powerful these machines are? "Consider the resources are limitless." said Erik Scott, a Senior Research Software Developer at RENCI. 

Previous work showed the success of CHAT in constructed and simulated data sets as well as real data sets. The program has been applied in several independent projects to search for the genetic basis (i.e., causal mutations) of and treatment targets for diseases such as Parkinson's disease, stroke, alcoholism, multiple sclerosis, lymphoid cancer, and lung cancer and smoking. These studies found that CHAT is more likely to be successful with phenotypes that have lower population prevalence. The next step is to test CHAT using additional real data sets as they become available. Our goal is to help establish the baseline rate for detecting clusters of individuals with long shared haplotypes and to establish collaboration to resequence several genes for a few subjects. 

When I first looked into the code of CHAT, my impression is that Kirk put into a lot of efforts to make this software fault tolerant when working with clusters. CHAT tries to break up the jobs to use the number of CPUs that are expected. If a job fails it will be restarted and is often broken up into smaller jobs. CHAT keeps track of finished jobs and tries to resume remaining or failed ones. Most output files have internal line count information, so that a corrupted file can be automatically detected. Files are usually checked once for completeness but also frequently checked for whether they are where they are supposed to be. The above settings are accomplished through a properties file and can be changed in some in the longest step (i.e., phasing). Any step can be reinitialized (organized as multiple beans in the properties file), but then all subsequent steps then need to reinitialized. The intermediate data is stored in a derby database.

<h2>Install CHAT 1.0 -- for debuggers</h2>
CHAT is developed using eclipse and maven, so eclipse is the best environment for debugging. The executable file is chat.jar.
First install maven and eclipse. You need to have a home repository for maven . For example, mine looks like '/home/linly/.m2/repository'. Kirk's source code is stored in <a href="https://svn.renci.org/snv">renci SVN repository</a>. You can open the SVN repository perspective of Eclipse, log into the above address and checkout CHAT. Do not close Eclipse. Open an SSH session and 'cd' to wherever you put the checked out program, i.e., the checked-out chat root directory. For example, mine is '/projects/sequence_analysis/vol4/CHAT_simGWAS/workspace/chat-1.0/'. Run 'mvn clean install eclipse:eclipse' in the command line. Go back to Eclipse, refresh you project in Eclipse with f5. Then go to Window -> Preferences -> Java -> Build Path -> Classpath. Create a new variable called 'M2_REPO' and the value is <your home directory>/.m2/repository. For example, mine looks like '/home/linly/.m2/repository'. Then in Eclipse at the "Package Explorer" perspective, right click the root of the CHAT project and choose "import" from the drop-down menu. Import each of the sub directories (i.e., chat-common, chat-prep, chat-core, etc) as an existing project, so that they are all imported into the workspace.

Second, create a jar with all the dependencies includes. Type 'mvn clean install assembly:assembly' at the shell command line (make sure you are in the chat root directory). You will find the .jar file in the /target sub-directory of the root directory, probably named as "chat-1.0-SNAPSHOT-bin.jar". Copy this .jar file to a place where it can be found by the envrionment variable $Path (i.e, make sure it is "in the PATH"). For example, I keep all execution files/application programs in the /bin folder of my home directory (/home/linly/bin), so I can use something like
<pre><code>cp target/chat-1.0-SNAPSHOT-bin.jar ~/bin/chat.jar</code></pre>
Note: do not forget to make the .jar actually executable by
<pre><code>chmod +x chat.jar</code></pre>

<h2>CHAT inputs</h2>
In the the chat root directory there is a test example folder called 'TestDebug' that can be copied to a workspace as a test use case. This folder contains a genotype file that has just the data for a region on chromosome that contains the lrrk2 locus. 48 of the subjects in the pedigree file have a LRRK2 mutation that causes parkinsonsin's disease. The file lrrk_samples_save list the subjects. Not all of them are included in the analysis as CHAT excludes closely related individuals (I will introduce how this is done later). Before running the test example, make sure you have done the following:
<ul>
<li>Import (by right click and choose import from the drop-down menu) an existing project into workspace for each of the sub directories. (i.e., chat-common, chat-prep, chat-core etc). The classes built in these directories are what that are actually executed.</li>
<li>Open the 'chat.properties' file in the 'TestDebug' folder and change the path for the workdir to the new path. For example, I put the 'TestDebug' folder in '/projects/sequence_analysis/vol4/CHAT_simGWAS/workspace/chat-1.0', so the second line of the 'chat.properties' file is correspondingly "workdir=/projects/sequence_analysis/vol4/CHAT_simGWAS/workspace/chat-1.0/TestDebug".</li>
</ul>
The "TestDebug" folder contains the minimal input files CHAT needed (specified at the beginning of the "CHAT.properties" file). If you prefer your own test data, please also create and format these files (see below for detailed instructions). There is no need to name your files using same extensions (e.g., .lgen, .map, or .sample) though. You can simply use ".txt" or nothing. In the source code of CHAT (written in Java),  DataSet.java inside chat-common contains functions (readChatDataSet, readLgenDataSet) that are used to parse these input files. Now let me introduce these files one by one.
<ul>
<li>A raw genotype file (also referred to as the lgen file) with tab or comma delimited columns:<br/>
     <i>chromID,pos,rs,subjectID,genotype[,CONFIDENCE]</i><br/>
A lgen file corresponds to a single chromosome and each line in the file describes a subject's genotype of a particular marker SNP on that chromosome. The first five columns (required) provide detailed information on a marker: its located chromosome, physical position, <a href="http://www.ncbi.nlm.nih.gov/books/NBK44417/">rs number</a>, ID of the subject (individual), and genotype. The genotype data should be in single char format (e.g. 0,1,2 for AA, AG, GG) or <a href="http://www.bioinformatics.org/sms/iupac.html ">the IUPAC format</a> (e.g., A,R,G for AA, AG, GG). See the code file below for more information. The last column (optional) gives a float-type confidence value that can be used to filter the data. This file SHOULD be gzipped (end with .gz) to save space (required by the program). </li>
<li>A LDU map file: tab or comma delimited columns:<br/>
     <i>chromID,pos,rs,ldumap (-999999 for unknown place holder),in use bit</i></li>
The first three columns have the same meanings as in the lgen file. The fourth column (ldumap) indicates a particular marker's LDU (linkage disequilibrium unit) map position. The last column indicates whether or not this record will be used in later analysis: 0 means no use and 1 means use. 
<li>A sample file (also referred to as the fam file): tab or comma delimited SubjectID, DX (disease affection) {0 as unknown,1 as unaffected/control,2 as affected/case},Sex {2 female,1 male, 0 unknown},in use bit {0,1}</li> 
<li>A code file (also referred to as the truth table or truth matrix) indicates genotype coding strategy used in the data set. The first line gives the codes that represent homozygous geneotypes (e.g., A,C,G,T for AA, CC, GG, TT). The second line gives the codes of all possible genotypes (e.g., A,C,G,K,M,R,S,T,W,Y,X, if the IUPAC format is applied). These are also the horizontal and vertical elements of the truth table/matrix (referred to as truth vectors). Such a table checks compatibility. Regarding the IUPAC format, an "R" genotype can be either an "A" or a "G" genotype , i.e., an "R" is compatible with an "A" or a "G" (denoted as R = A or G). Thus, Y=C or T, S=G or C, W=A or T, K=G or T, M=A or C. In order to indicate that A is compatible with M, R, and X, "1" is assigned to the matrix cell AM, MA, AR, RA, AX, and XA. In contrast, "0" indicates incompatibility. Thus, a IUPAC code file should look like below (note that the placement of comma is critical for CHAT to correctly parse the truth matrix):
<pre><code>
,A,C,G,T
,A,C,G,K,M,R,S,T,W,Y,X 
A,1,0,0,0,1,1,0,0,1,0,1
C,0,1,0,0,1,0,1,0,0,1,1
G,0,0,1,1,0,1,1,0,0,0,1
K,0,0,1,1,0,1,1,1,1,1,1
M,1,1,0,0,1,1,1,0,1,1,1
R,1,0,1,1,1,1,1,0,1,0,1
S,0,1,1,1,0,1,1,0,0,1,1
T,0,0,0,1,0,0,0,1,1,1,1
W,1,0,0,1,1,1,0,1,1,1,1
Y,0,1,0,1,1,0,1,1,1,1,1
X,1,1,1,1,1,1,1,1,1,1,1
</code></pre></li>
</ul>

<h2>Play with CHAT -- Major modules/steps</h2>
<h3>Module 1</h3>
The first step/module is to convert input files into CHAT accepted format. It is controlled by the CHAT_prep.xml file in the same folder. The file defines all the <a href="http://stackoverflow.com/questions/17193365/what-in-the-world-are-spring-beans">spring beans</a> used to accomplished this step. Users can skip a particular bean by commenting out the corresponding ref bean line in the threadList of the XML file using <!-- statement -->. <b>
Note: (a) In most of the steps called in CHAT.xml and CHAT_prep.xml there is a Main that can be edited so that the step can be run one at a time. I'll show you how to do that in details later.<br/>
(b) The step of building LDU map in this module is done by a third-party executable file called "ldmapper1", which you can find in the 'Notes_Resources' folder in the root directory. Move it to wherever convenient for you and add its path to the environment variable PATH, so that this file can be located. Also, building LDU map requires enough memory space, so you may want to grab a compute node of the cluster to run this module on. If you are going to run the module using Eclipse debug perspective, you need to grab an interactive node. Take a look at <a href="http://lybird300.github.io/2015/10/01/cluster-slurm.html">this post</a> on how to do that.

In Eclipse, to run using the debug perspective, go to run>debug_configerations. Right click on "java application" and a new Dialog box will pop up allowing you to create a new configuration for debug. Name the new instance CHAT_prep. CLick the browse button next to projects and select chat-commons. Next to the Main Class text box select Main-org.renci.chat. The change the project to chat-prep. (Main is in commons and chat-prep is dependent on it). Then click arguments tag. In the Program arguemnt type 'CHAT_prep.xml'; in the vm arguments you can add something like '-Xmx6g'. Change the working directory to wherever you have put the 'TestDebug' folder (At the bottome of the Arguments tab, there is a place allowing you to modify Working directory. Click on "Other" and specify the path). Click apply. Now you can click the 'Debug' button to start running the app or click the 'close' button to do this later.  

The first three beans check the sanity of input files (users can scroll down in the "CHAT_prep.xml" file to see and modify the properties of each bean). "CheckLgenStructureRunnable" conducts sanity check on the lgen file. If there are any problematic genotype records (i.e., lines) in the file, the process will be terminated so that users can review detected problems, which are recorded in a "problemGenotypes.txt" file in the same folder. If no problem is detected, there won't be such a file (created and then deleted by the program). All "filtered" genotype records (obtained by stripping problematic and redundant lines) are outputted into a file named by adding a prefix "Filtered" to the the original sample lgen name. This file has the same format as the old file. If the user is willing to ignore (instead of trying to modify) all identified problem lines, he or she can set the "projectRawLongDataFileName" field in CHAT.properties (which is the field that indicates the lgen file to be used) to the file that contains all filtered genotype records (i.e., the one whose name starts with "Filtered"). Three other files can also be created during the process, although users can choose not to write any of them by commenting out corresponding property lines or setting the value to "" in the CHAT_prep.xml file. Among the three files, "GenotypeContainsChrom.txt" stores involved chromosomes (ordered by chromID), each per line. (b) "GenotypeContainsSamples.txt" stores involved subjects (ordered by subjectID), each per line with the format:<br/>
<i>subjectID,0 (place holder for unknown disease affection state),0 (place holder for unknown sex),1</i><br/>
(c) "GenotypeContainsSNPs.txt" stores involved marker SNPs (ordered by marker position), each per line with the format:<br/>
<i>chromID,pos,rsnumber,-77777.0 (place holder for unknown LDU map position),1</i><br/>

The second bean "CheckMapStructureRunnable" conducts sanity check on the LDU map file (required information and their number format and redundancy). If there are any problematic map elements in the file (one element as a line), the process will be terminated so that users can review detected problems (recorded in a "ProblemMapRecords.txt" file in the same folder). This bean mainly checks whether each record (i.e., each line) in the file has a unique rs number (the 3rd column/field), i.e., whether each SNP uniquely maps to a location. Two maps (data structure) are also created connecting each SNP (identified by its rs number) to its located chromosome (the 1st column/field) and physical position on that chromosome (the 2nd column/field) respectively. All "filtered" (i.e., non-problematic) map elements are sorted using their rs numbers and outputted into a file named by adding a prefix "FilteredSorted" to the old map file. This file has the same format as the old file. If the user is willing to ignore (instead of trying to modify) all identified problem lines, he or she can set the "projectMap" field in CHAT.properties (which is the field that indicates the map file to be used)  to the file that contains all filtered map records (i.e., the one whose name starts with "FilteredSorted"). Additionally, the bean can create a "MapContains<old map file name>.chrom" file listing all involved chromosomes (ordered by chromID), each per line (without redundancy). If users prefer, the bean also checks to see whether the map file contains all the SNPs in the "GenotypesContainsSNPs.txt" file outputted by the first bean (of course then that file must already exist). Any SNP in the previous file but missing in the map file will be outputted to a "SnpIdInGenotypeNotInMap.txt" file that has the same format as the previous file. If there are any SNPs mapped to more than one position or duplicate entries in the map, their information will be outputted to the screen  (i.e., standard output) and the process will be terminated.

The third bean "CheckFamStructureRunnable" conducts sanity check on the sample file (required information and their number format and redundancy). Any problematic sample element in the file (as a line) will be assigned -9 to its "include" "dx" and "sex" fields, so that it won't pass validity test. All problematic samples are outputted to a separate file named "problemSample.txt"; given no problem, this file will be automatically deleted. This bean mainly checks whether each record (i.e., each line) in the sample file has a unique sample ID (the 1st column/field). Duplicated sample lines are stripped and put in a file named by adding a prefix "dupSamples" to the original sample file name. All non-redundant sample elements are outputted into a file named by adding a prefix "FilteredSorted" to the old sample file; the list is sorted in the order of the "include" "dx" "sample ID" and "sex" fields subsequently. This file has the same format as the old file. If the user is willing to ignore (instead of trying to modify) all identified problem lines, he or she can set the "projectSamples" field in CHAT.properties (which is the field that indicates the map file to be used)  to the file that contains all filtered map records (i.e., the one whose name starts with "FilteredSorted"). If users prefer, this bean will check to see whether the sample file contains all the samples in the "GenotypesContainsSamples.txt" file outputted by the first bean. Missing samples will be outputted to a "SamplesIdInGenotypeNotInFamilyFile.txt" file that has the same format as the previous file but the "sex" and "dx" fileds of these sample records are changed to unknown and the "include" field to 0 (not included). Then the process will be terminated so that users can review these mismatched samples.

Then the filtered input information is further checked, reorganized, and filtered. This is accomplished by two beans. The first bean "MakeChromSpecificChatFromLgen" collects information from the above output files and rearranges them for each chromosome. The records in the filtered lgen file are distributed into different txt files, each of which corresponds to one chromosome ("<chromID>.txt"), with every record (line) formatted as<br/>
<i>chromID,pos,rs number,subjectID,genotype,confidence</i>
<br/>. These txt files are stored in a sub-directory of the work directory (i.e., TestDebug) named "TempChromosomeSpecificRawData". If users are only interested in some but not all of the chromosomes in the data set, they can specify the chromosome(s) of interest beforehand by putting them in a separate file (see the "projectChromosomeList" field of the CHAT.properties file). Then only the information of specified chromosomes will be processed. Users can also filter the raw lgen records based on their QC scores (the "confidence" field). This bean also checks whether (a) every SNP has corresponding records in both the filtered lgen file and the filtered map file, and (b) each sample has a unique genotype at every spot (identified by its rs number) on one chromosome. In the latter case, given a single chromosome, there should not be multiple different records regarding a subject's genotype at the same spot. This kind of errors in the data set are referred to as "subject-snp discordant genotype" and will be outputted to a file named "Discord_<chromID>.txt" in the "chromosomeSpecificData" directory. In this file, each discordant subject-snp pair is described by three fields:<br/>
<i>subjectID,rs number of the SNP,occurrence of this subject-SNP pair in the data set</i>
When there is a discordant genotype, it will be coded as unknown (e.g., "X" in IUPAC). The major task of this bean is to use write input data files for CHAT. Each CHAT data file is converted from a previous "<chromID>.txt" file. Thus, it is also related with one chromosome and named after that chromosome ("<chromID>.txt"). The file starts with four lines: the first line aggregates all subject IDs separated by comma; the second line has all disease affect status (corresponding to subjects in the first line) separated by comma; the third line contains the "sex" field value of all subjects; the fourth line combines all "include" field values. Then are all SNP records, each per line in the form of<br/>
<i>chromID,pos,rs number,LDU map position,include or not (i.e., used or not),all subjects' genotypes of this SNP</i><br/>
The last field is a string of genotypes. After writing all CHAT data files to the "chromosomeSpecificData" folder, the program will delete the  "TempChromosomeSpecificRawData" directory to save space.

The second bean "FilterChromSpecificChat" applies four filters on CHAT data files (also referred to as chromosome specific files). Users can skip any of the filters by changing its corresponding value to a negative number or by commenting out the property line. Users can also specify the order in which these filters will be applied through the values of order properties (i.e., properties named as "***Order") in CHAT_prep.xml. Before filtering, this bean also conducts regular sanity check. Any SNP record (starting from the 5th line in a CHAT data file) with more or less than 6 fields (see above) will be considered invalid and read into the memory as the following<br/>
<i>"",-9,''invalid",-99999 (a predefined code meaning excluding this SNP from LDU map"),0 (i.e., not to be included)</i>
This bean also identifies and keeps records of SNPs and samples/subjects with more than 50% missing genotypes (IUPAC code "X") in the data set (referred to as "almost empty" SNPs and samples). The filtering introduced below are conducted on the rest of the data (samples and SNPs that have less than 50% missing genotypes). Now let's get to the "real business" of this bean, i.e., the four filters implemented by four functions. 
<ul>
<li>Hardy-Weinberg Equilibrium (not applicable for the X chromosome): For each SNP, the filter function first reads through samples to find out which codes (in the truth vector) represent the TWO homozygotes and one heterozygote regarding that SNP (denoted as a1, a2, and a12 in Java implementation; notably, the program assumes that all SNPs are biallelic. It will give an error message and stop once encountering a multi-allelic SNP). Then the filter function counts the occurrences of a1, a2, and a12 in all control samples (i.e., value of the "dx" field is not "2") and applies an exact test on the HWE of that SNP. The exact test for HWE has been mentioned in many articles, such as Emigh, T. H., 1980. A comparison of tests for Hardy-Weinberg equilibrium. Biometrics 36 627–642, or <a href="http://www.ncbi.nlm.nih.gov/pubmed/15789306">A note on exact tests of Hardy-Weinberg equilibrium</a>. If the test result cannot exceed a user-defined threshold, the SNP will be excluded from further analysis (set the "include" field to be 0)</li>
<li>Monomorphic SNPs: this filter function removes SNPs whose minor allele frequency (MAF) is smaller or equal to a user-defined threshold. A genotype code compatible with both a1 and a2 will be counted twice. (Note: the default MAF threshold is 0.01; since our simulated GWAS datasets contain only common variants (MAF >= 0.05) obtained using Haploview.tagger algorithm, all SNPs should be able to pass this filter.)</li>
<li>Missing SNPs: this filter function remove any SNP record (from the map attribute of a DataSet object) whose number of missing genotypes exceeds a user-defined threshold (by changing the "include" field from 1 to 0)</li>
<li>Missing samples: this filter function remove any sample record (from the sample attribute of a DataSet object) whose number of missing genotypes exceeds a user-defined threshold (by changing the "include" field from 1 to 0)</li>
</ul>
After the filtering, old chromosome specific data files (i.e., CHAT data files) are moved to a Backup subdirectory of the ChromosomeSpecificData directory. New CHAT data files will replace old corresponding ones (same name and format but with modified "include" fields; SNPs that have been filtered out will have include == 0) in this directory.

The next step is to build an LDU map, which is a genetics linkage disequilibrium map measured in LD units (LDU), for every chromosome based on CHAT data files. Recall that each CHAT data file contains SNP information of one single chromosome, one SNP record per line starting from the 5th line. (Check how to build a LDU map in <a href="http://www.pnas.org/content/102/33/11835.full">this article</a>); only female samples are used to make X-chromosome LDU map). You can change names of the directories and files involved, but you have to do it consistently for all three beans introduced below that implement this step. At the time being we rely on an enternal executable program called "ldmapper1" to do the heavy work. The first bean "makeLDMaps" intends to prepare and manage cluster-running jobs around this enternal software. Kirk used a database object (implemented by <a href="https://en.wikipedia.org/wiki/Apache_Derby">Aphache Derby (Java DB)</a> that supports <a href="https://en.wikipedia.org/wiki/Java_Database_Connectivity">JDBC</a> and <a href="https://en.wikipedia.org/wiki/SQL">SQL</a> as programming APIs) to store and manage all the LDU mapping jobs. He distinguished two types of Derby database objects in his code: one for LDU jobs (here) and the other for CHAT jobs (discussed later). They are different in the specific SQL commands they used for database initialization and management (see chat-common/src/main/java/org/renci/chat/derby/CHATDBApp.java).

The database for LDU jobs is named as "lduDB" and its contents are stored in a "lduDB" subfolder of the working directory. SQL statements are constructed as strings and executed for various purposes. First of all, we will break the entire chromosome into multiple segments and assign a job for each segment. To do so, an LDUJobsPlan table is built inside the database containing all these jobs; each record in the table has several fields such as job name, startMapIndex and endMapIndex of the chromosomal segment, number of SNPs on that segment (not every site is a SNP), and a field indicating whether the job is "done". Right now the LDU map is built on control samples only. 

 
 
<h2>Weak points</h2>
CHAT can only handle biallelic SNPs (check the filterHWE function in chat/common/DataSet.java). How can we improve that? Is there a HW equilibrium testing method that accommodate multiallelic SNPs?

